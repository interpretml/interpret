- look for any final features/fixes to include before the release:
  - check internal notes
  - check github issues
  - check github pull requests
  - check existing documentation

- run extra tests:
  - python exact value comparison tests in stash
  - C++ exact value comparison tests in stash
  - console tests
  - compare benchmark to previous known release (v0.4.0 is a validated release)

- IMPORTANT: check that the linux shared library is manylinux:
  - in azure-pipelines, under the published artifacts, under asm-x64-ubuntu-*, open libebm_linux_x64.s
  - look for the section "Version References"
  - if there is anything above GLIBC_2.5 (GLIBC_2.4 is ok), then we probably want to add a wrapper

- update version numbers for R, PyPi, npm(interpret-inline):
  - R/DESCRIPTION (also update the date!)
  - python/interpret/setup.py
  - python/interpret-core/setup.py
  - python/interpret-core/interpret/_version.py
  - shared/vis/package.json
- update the CHANGELOG.md file

- download the following into a new directory. From azure-pipelines, in "published artifacts":
  - docs: download the entire "docs" artifact as a zip file
  - npm: interpretml-interpret-inline-*.tgz
  - R: interpret_*.tar.gz
  - sdist: interpret-*.tar.gz
  - sdist: interpret-core-*.tar.gz
  - bdist: interpret-*-py3-none-any.whl
  - bdist: interpret_core-*-py3-none-any.whl

- test the bdist:
  - open anaconda console window
  - cd <PACKAGE_DOWNLOAD_DIRECTORY>
  - conda env list  # see the list of existing environments
  - conda create --yes --name interpret_N python=3.9
  - conda activate interpret_N
  - pip install interpret_core-*-py3-none-any.whl[required,debug,notebook,plotly,lime,sensitivity,shap,ebm,linear,decisiontree,treeinterpreter,dash,skoperules,testing]
  - cd <REPO_ROOT>
  - cd examples/python
  - jupyter notebook
  - open all the example notebooks, run them, and check the visualizations
  - clear all outputs on all notebooks
  - add the following lines to the top of each notebook:
from interpret import set_visualize_provider
from interpret.provider import InlineProvider
set_visualize_provider(InlineProvider())
  - re-run all the notebooks and check the visualizations again

- test the sdist:
  - open anaconda console window
  - cd <PACKAGE_DOWNLOAD_DIRECTORY>
  - conda env list  # see the list of existing environments
  - conda create --name interpret_N python=3.10
  - conda activate interpret_N
  - IN WINDOWS: get the Visual studio environment with: "C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\VC\Auxiliary\Build\vcvars64.bat"
  - pip install interpret-core-*.tar.gz[required,debug,notebook,plotly,lime,sensitivity,shap,ebm,linear,decisiontree,treeinterpreter,dash,skoperules,testing]
  - cd <REPO_ROOT>
  - cd examples/python/notebooks
  - jupyter notebook
  - open all the example notebooks, run them, and check the visualizations
  - clear all outputs on all notebooks
  - add the following lines to the top of each notebook:
      from interpret import set_visualize_provider
      from interpret.provider import InlineProvider
      set_visualize_provider(InlineProvider())
  - re-run all the notebooks and check the visualizations again

- test the R package
  - run the "--as-cran" checks on the downloaded package:
    - TODO: add this as a step in the build pipeline so that we can just check it there, but make it not fail the pipeline if it fails since we'd then have to keep updating the date in the package
    - cd <PACKAGE_DOWNLOAD_DIRECTORY>
    - R CMD check --as-cran -o ../tmp/R interpret_*.tar.gz
  - upload the R package at <PACKAGE_DOWNLOAD_DIRECTORY> to test on multiple platforms in: https://builder.r-hub.io
  - In particular, the "Oracle Developer Studio 12.6" is worth testing as that C++ compiler is picky, and CRAN tests it

- check the docs
  - cd <PACKAGE_DOWNLOAD_DIRECTORY>
  - unzip the docs.zip file
  - open one of the html files and go to the first document in the list
  - do a side by side browser comparison to the existing documentation at: https://interpret.ml/docs
  - clone the repo: https://github.com/interpretml/docs
  - delete all the files, except possibly for ".gitignore" (TODO: can we remove .gitignore even since all the files are uploaded?)
  - copy the new files into that repo, BUT DO NOT PUSH YET

- publish on NPM
  - cd <PACKAGE_DOWNLOAD_DIRECTORY>
  - we can't re-use previously published versions, but the visualization code is likely to remain unchanged, and our 
    NPM package isn't really directly accessed by users, and it's used by all our different language packages, so publish this first
  - to publish:
    - npm login
    - it will ask for our email, which for us is the @outlook.com email, then it will ask for the "one-time password from your authenticator app" 
      which is a confusing way to say that it has emailed us a code.
    - npm publish interpretml-interpret-inline-*.tgz
    - verify that is was published at: https://www.npmjs.com/package/@interpretml/interpret-inline

- test the NPM interpret-inline.js
  - TODO: how do we specify that the interpret python code uses the NPM interpret-inline.js instead of the local interpret-inline.js?
  - re-test the bdist as above, but with the cloud interpret-inline.js

- publish R package on CRAN:
  - CRAN is very picky on warnings, so this is our first publicly visible release so that the version numbers will more likely match up with the python releases
  - submit to CRAN at: https://cran.r-project.org/submit.html
  - login to @outlook.com email to accept the publication
  - wait a day (or until it's been checked)
  - check at: https://cran.r-project.org/package=interpret
  - wait 2-3 days if possible to see if CRAN has any issues at: https://cran.r-project.org/web/checks/check_results_interpret.html

- publish on conda-forge:
  - we can re-do a release with the same version number, unlike pypi, so release this first for testing
  - PRE:
    - get the git ID:
      - go to: https://github.com/interpretml/interpret
      - click "commits"
      - click "Copy the full SHA" icon
      - open an ubuntu window
      - get the sha256 for the tar.gz: curl -sL https://github.com/interpretml/interpret/archive/<GIT_SHA>.tar.gz | openssl sha256
  - libebm:
    - fork into a new github username repo from (if not already forked): https://github.com/conda-forge/libebm-feedstock
    - edit the local repo in github: https://github.com/<USERNAME>/libebm-feedstock/blob/main/recipe/meta.yaml
      - update the version number
      - update the github URL with the git hash
      - update the sha256 with the tar.gz SHA hash
      - set build number to 0
      - POSSIBLY: re-enable any libebm tests
      - commit the changes
    - on the "code" page, click "contribute" to make a PR back to the conda-forge repo in: https://github.com/<USERNAME>/libebm-feedstock/blob/main/recipe/meta.yaml
    - if a big change was made to the recipe, then add the comment: @conda-forge-admin, please rerender
    - wait for conda-forge the build the PR. It it works, merge the PR
    - wait for the merged code to build. conda-forge will publish it to conda.org if the build completes successfully
    - check that the package was uploaded at: https://anaconda.org/conda-forge/libebm
    - wait a bit longer (30 minutes seems to sometimes work) for the CDN to have an updated copy. If a rebuild is needed use: @conda-forge-admin, please restart ci
  - interpret-core:
    - fork into a new github username repo from (if not already forked): https://github.com/conda-forge/interpret-core-feedstock
    - edit the local repo in github: https://github.com/<USERNAME>/interpret-core-feedstock/blob/main/recipe/meta.yaml
      - update the version number
      - update the github URL with the git hash
      - update the sha256 with the tar.gz SHA hash
      - set build number to 0
      - POSSIBLY: re-enable the pytest tests, and set "pip check" on
      - commit the changes
    - on the "code" page, click "contribute" to make a PR back to the conda-forge repo in: https://github.com/<USERNAME>/interpret-core-feedstock/blob/main/recipe/meta.yaml 
    - if a big change was made to the recipe, then add the comment: @conda-forge-admin, please rerender
    - wait for conda-forge the build the PR. It it works, merge the PR
    - wait for the merged code to build. conda-forge will publish it to conda.org if the build completes successfully
    - check that the package was uploaded at: https://anaconda.org/conda-forge/interpret-core
    - wait a bit longer (30 minutes seems to sometimes work) for the CDN to have an updated copy. If a rebuild is needed use: @conda-forge-admin, please restart ci
  - interpret:
    - fork into a new github username repo from (if not already forked): https://github.com/conda-forge/interpret-feedstock
    - edit the local repo in github: https://github.com/<USERNAME>/interpret-feedstock/blob/main/recipe/meta.yaml
      - update the version number
      - update the github URL with the git hash
      - update the sha256 with the tar.gz SHA hash
      - set build number to 0
      - POSSIBLY: re-enable the pytest tests, and set "pip check" on
      - commit the changes
    - on the "code" page, click "contribute" to make a PR back to the conda-forge repo in: https://github.com/<USERNAME>/interpret-feedstock/blob/main/recipe/meta.yaml 
    - if a big change was made to the recipe, then add the comment: @conda-forge-admin, please rerender
    - wait for conda-forge the build the PR. It it works, merge the PR
    - wait for the merged code to build. conda-forge will publish it to conda.org if the build completes successfully
    - check that the package was uploaded at: https://anaconda.org/conda-forge/interpret
    - wait a bit longer (30 minutes seems to sometimes work) for the CDN to have an updated copy. If a rebuild is needed use: @conda-forge-admin, please restart ci

- test the conda-forge release locally since colab doesn't seem to allow libebm.so to be loadable from conda:
  - ? Is there any way to install and run the conda package in a cloud notebook so that we can test the NPM inline js package?
  - open anaconda console window
  - conda env list  # see the list of existing environments
  - conda create --yes --name interpret_N python=3.9
  - conda activate interpret_N
  - conda install --yes -c conda-forge interpret
  - cd <REPO_ROOT>
  - cd examples/python
  - jupyter notebook
  - open all the example notebooks, run them, and check the visualizations
  - clear all outputs on all notebooks
  - add the following lines to the top of each notebook:
from interpret import set_visualize_provider
from interpret.provider import InlineProvider
set_visualize_provider(InlineProvider())
  - re-run all the notebooks and check the visualizations again

- publish on PyPi:
  - upload the sdist and bdist together:
    - cd <PACKAGE_DOWNLOAD_DIRECTORY>
    - pip install twine
    - in an otherwise empty directory that only contains the 4 files (interpret bdist, interpret-core bdist, interpret sdist, interpret-core sdist), run
    - twine upload interpret*
    - fill in the username/password

- test pypi release on colab:
  - https://githubtocolab.com/interpretml/interpret/blob/develop/examples/python/Interpretable_Classification_Methods.ipynb

- test pypi release locally:
  - open anaconda console window
  - conda env list  # see the list of existing environments
  - conda create --yes --name interpret_N python=3.9
  - conda activate interpret_N
  - pip install interpret
  - cd <REPO_ROOT>
  - cd examples/python
  - jupyter notebook
  - open all the example notebooks, run them, and check the visualizations
  - clear all outputs on all notebooks
  - add the following lines to the top of each notebook:
from interpret import set_visualize_provider
from interpret.provider import InlineProvider
set_visualize_provider(InlineProvider())
  - re-run all the notebooks and check the visualizations again

- publish the docs:
  - delete all the files in the docs repo (except the .git directory)
  - copy the docs that we got from the azure build pipeline into the docs repo
  - git add --all
  - git commit -m "update docs to v0.."
  - compare the local html files with https://interpret.ml/docs
  - git push
  - verify the files are uploaded at: https://interpret.ml/docs

- in github:
  - maybe wait a day or two to see if any issues come up before advertizing the release this way
  - select the "develop" branch
  - in the main code window, click on "tags" next to the branch
  - click on "releases"
  - click on "Draft a new release"
  - choose a tag in the format "v0.x.x", and allow it to be created
  - set the release title to "Version 0.x.x"
  - paste the CHANGELOG changes into the "Describe this release" window
  - preview it just to be sure
  - click "publish release".  Github will automatically attach the source code .zip and .tar.gz files
- in your local git
  - pull/fetch to get the "v0.x.x" tag that github added to the repo
  - switch to the "main" branch
  - merge "develop" into "main" (this will also cary along with it the tag)
  - push the "main" branch

